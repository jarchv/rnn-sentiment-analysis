{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from http://nbviewer.jupyter.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/outofcore_modelpersistence.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The IMDb Movie Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train a simple logistic regression model to classify movie reviews from the 50k IMDb review dataset that has been collected by Maas et. al.\n",
    "\n",
    "> AL Maas, RE Daly, PT Pham, D Huang, AY Ng, and C Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human Language Technologies, pages 142â€“150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics\n",
    "\n",
    "[Source: http://ai.stanford.edu/~amaas/data/sentiment/]\n",
    "\n",
    "The dataset consists of 50,000 movie reviews from the original \"train\" and \"test\" subdirectories. The class labels are binary (1=positive and 0=negative) and contain 25,000 positive and 25,000 negative movie reviews, respectively.\n",
    "For simplicity, I assembled the reviews in a single CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('shuffled_movie_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us shuffle the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available',\n",
       "       1], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a generator that returns the document body and the corresponding class label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conform that the `stream_docs` function fetches the documents as intended, let us execute the following code snippet before we implement the `get_minibatch` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we confirmed that our `stream_docs` functions works, we will now implement a `get_minibatch` function to fetch a specified number (`size`) of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    for _ in range(size):\n",
    "        text, label = next(doc_stream)\n",
    "        docs.append(text)\n",
    "        y.append(label)\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a simple `tokenizer` that splits the text into individual word tokens. Furthermore, we will use some simple regular expression to remove HTML markup and all non-letter characters but \"emoticons,\" convert the text to lower case, remove stopwords, and apply the Porter stemming algorithm to convert the words into their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem import WordNetLemmatizer\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub(r\"it's\", \" it is\", text)\n",
    "    text = re.sub(r\"that's\", \" that is\", text)\n",
    "    text = re.sub(r\"\\'s\", \" 's\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"won't\", \" will not\", text)\n",
    "    text = re.sub(r\"don't\", \" do not\", text)\n",
    "    text = re.sub(r\"can't\", \" can not\", text)\n",
    "    text = re.sub(r\"cannot\", \" can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" n\\'t\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    text = [w for w in text.split()]\n",
    "    \n",
    "    #tokenized = [wordnet_lemmatizer.lemmatize(w) for w in text]\n",
    "    return text\n",
    "    #return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it at try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'test',\n",
       " 'and',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'what',\n",
       " 'will',\n",
       " 'happens']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"This :) is a <br /> test! :-) and I'm not sure what will happens</br>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 0.00%\r",
      " 0.00%\r",
      " 0.01%\r",
      " 0.01%\r",
      " 0.01%\r",
      " 0.01%\r",
      " 0.01%\r",
      " 0.02%\r",
      " 0.02%\r",
      " 0.02%\r",
      " 0.02%\r",
      " 0.02%\r",
      " 0.03%\r",
      " 0.03%\r",
      " 0.03%\r",
      " 0.03%\r",
      " 0.03%\r",
      " 0.04%\r",
      " 0.04%\r",
      " 0.04%\r",
      " 0.04%\r",
      " 0.04%\r",
      " 0.05%\r",
      " 0.05%\r",
      " 0.05%\r",
      " 0.05%\r",
      " 0.05%\r",
      " 0.06%\r",
      " 0.06%\r",
      " 0.06%\r",
      " 0.06%\r",
      " 0.06%\r",
      " 0.07%\r",
      " 0.07%\r",
      " 0.07%\r",
      " 0.07%\r",
      " 0.07%\r",
      " 0.08%\r",
      " 0.08%\r",
      " 0.08%\r",
      " 0.08%\r",
      " 0.08%\r",
      " 0.09%\r",
      " 0.09%\r",
      " 0.09%\r",
      " 0.09%\r",
      " 0.09%\r",
      " 0.10%\r",
      " 0.10%\r",
      " 0.10%\r",
      " 0.10%\r",
      " 0.10%\r",
      " 0.11%\r",
      " 0.11%\r",
      " 0.11%\r",
      " 0.11%\r",
      " 0.11%\r",
      " 0.12%\r",
      " 0.12%\r",
      " 0.12%\r",
      " 0.12%\r",
      " 0.12%\r",
      " 0.13%\r",
      " 0.13%\r",
      " 0.13%\r",
      " 0.13%\r",
      " 0.13%\r",
      " 0.14%\r",
      " 0.14%\r",
      " 0.14%\r",
      " 0.14%\r",
      " 0.14%\r",
      " 0.15%\r",
      " 0.15%\r",
      " 0.15%\r",
      " 0.15%\r",
      " 0.15%\r",
      " 0.16%\r",
      " 0.16%\r",
      " 0.16%\r",
      " 0.16%\r",
      " 0.16%\r",
      " 0.17%\r",
      " 0.17%\r",
      " 0.17%\r",
      " 0.17%\r",
      " 0.17%\r",
      " 0.18%\r",
      " 0.18%\r",
      " 0.18%\r",
      " 0.18%\r",
      " 0.18%\r",
      " 0.19%\r",
      " 0.19%\r",
      " 0.19%\r",
      " 0.19%\r",
      " 0.19%\r",
      " 0.20%\r",
      " 0.20%\r",
      " 0.20%\r",
      " 0.20%\r",
      " 0.20%\r",
      " 0.21%\r",
      " 0.21%\r",
      " 0.21%\r",
      " 0.21%\r",
      " 0.21%\r",
      " 0.22%\r",
      " 0.22%\r",
      " 0.22%\r",
      " 0.22%\r",
      " 0.22%\r",
      " 0.23%\r",
      " 0.23%\r",
      " 0.23%\r",
      " 0.23%\r",
      " 0.23%\r",
      " 0.24%\r",
      " 0.24%\r",
      " 0.24%\r",
      " 0.24%\r",
      " 0.24%\r",
      " 0.25%\r",
      " 0.25%\r",
      " 0.25%\r",
      " 0.25%\r",
      " 0.25%\r",
      " 0.26%\r",
      " 0.26%\r",
      " 0.26%\r",
      " 0.26%\r",
      " 0.26%\r",
      " 0.27%\r",
      " 0.27%\r",
      " 0.27%\r",
      " 0.27%\r",
      " 0.27%\r",
      " 0.28%\r",
      " 0.28%\r",
      " 0.28%\r",
      " 0.28%\r",
      " 0.28%\r",
      " 0.29%\r",
      " 0.29%\r",
      " 0.29%\r",
      " 0.29%\r",
      " 0.29%\r",
      " 0.30%\r",
      " 0.30%\r",
      " 0.30%\r",
      " 0.30%\r",
      " 0.30%\r",
      " 0.31%\r",
      " 0.31%\r",
      " 0.31%\r",
      " 0.31%\r",
      " 0.31%\r",
      " 0.32%\r",
      " 0.32%\r",
      " 0.32%\r",
      " 0.32%\r",
      " 0.32%\r",
      " 0.33%\r",
      " 0.33%\r",
      " 0.33%\r",
      " 0.33%\r",
      " 0.33%\r",
      " 0.34%\r",
      " 0.34%\r",
      " 0.34%\r",
      " 0.34%\r",
      " 0.34%\r",
      " 0.35%\r",
      " 0.35%\r",
      " 0.35%\r",
      " 0.35%\r",
      " 0.35%\r",
      " 0.36%\r",
      " 0.36%\r",
      " 0.36%\r",
      " 0.36%\r",
      " 0.36%\r",
      " 0.37%\r",
      " 0.37%\r",
      " 0.37%\r",
      " 0.37%\r",
      " 0.37%\r",
      " 0.38%\r",
      " 0.38%\r",
      " 0.38%\r",
      " 0.38%\r",
      " 0.38%\r",
      " 0.39%\r",
      " 0.39%\r",
      " 0.39%\r",
      " 0.39%\r",
      " 0.39%\r",
      " 0.40%\r",
      " 0.40%\r",
      " 0.40%\r",
      " 0.40%\r",
      " 0.40%\r",
      " 0.41%\r",
      " 0.41%\r",
      " 0.41%\r",
      " 0.41%\r",
      " 0.41%\r",
      " 0.42%\r",
      " 0.42%\r",
      " 0.42%\r",
      " 0.42%\r",
      " 0.42%\r",
      " 0.43%\r",
      " 0.43%\r",
      " 0.43%\r",
      " 0.43%\r",
      " 0.43%\r",
      " 0.44%\r",
      " 0.44%\r",
      " 0.44%\r",
      " 0.44%\r",
      " 0.44%\r",
      " 0.45%\r",
      " 0.45%\r",
      " 0.45%\r",
      " 0.45%\r",
      " 0.45%\r",
      " 0.46%\r",
      " 0.46%\r",
      " 0.46%\r",
      " 0.46%\r",
      " 0.46%\r",
      " 0.47%\r",
      " 0.47%\r",
      " 0.47%\r",
      " 0.47%\r",
      " 0.47%\r",
      " 0.48%\r",
      " 0.48%\r",
      " 0.48%\r",
      " 0.48%\r",
      " 0.48%\r",
      " 0.49%\r",
      " 0.49%\r",
      " 0.49%\r",
      " 0.49%\r",
      " 0.49%\r",
      " 0.50%\r",
      " 0.50%\r",
      " 0.50%\r",
      " 0.50%\r",
      " 0.50%\r",
      " 0.51%\r",
      " 0.51%\r",
      " 0.51%\r",
      " 0.51%\r",
      " 0.51%\r",
      " 0.52%\r",
      " 0.52%\r",
      " 0.52%\r",
      " 0.52%\r",
      " 0.52%\r",
      " 0.53%\r",
      " 0.53%\r",
      " 0.53%\r",
      " 0.53%\r",
      " 0.53%\r",
      " 0.54%\r",
      " 0.54%\r",
      " 0.54%\r",
      " 0.54%\r",
      " 0.54%\r",
      " 0.55%\r",
      " 0.55%\r",
      " 0.55%\r",
      " 0.55%\r",
      " 0.55%\r",
      " 0.56%\r",
      " 0.56%\r",
      " 0.56%\r",
      " 0.56%\r",
      " 0.56%\r",
      " 0.57%\r",
      " 0.57%\r",
      " 0.57%\r",
      " 0.57%\r",
      " 0.57%\r",
      " 0.58%\r",
      " 0.58%\r",
      " 0.58%\r",
      " 0.58%\r",
      " 0.58%\r",
      " 0.59%\r",
      " 0.59%\r",
      " 0.59%\r",
      " 0.59%\r",
      " 0.59%\r",
      " 0.60%\r",
      " 0.60%\r",
      " 0.60%\r",
      " 0.60%\r",
      " 0.60%\r",
      " 0.61%\r",
      " 0.61%\r",
      " 0.61%\r",
      " 0.61%\r",
      " 0.61%\r",
      " 0.62%\r",
      " 0.62%\r",
      " 0.62%\r",
      " 0.62%\r",
      " 0.62%\r",
      " 0.63%\r",
      " 0.63%\r",
      " 0.63%\r",
      " 0.63%\r",
      " 0.63%\r",
      " 0.64%\r",
      " 0.64%\r",
      " 0.64%\r",
      " 0.64%\r",
      " 0.64%\r",
      " 0.65%\r",
      " 0.65%\r",
      " 0.65%\r",
      " 0.65%\r",
      " 0.65%\r",
      " 0.66%\r",
      " 0.66%\r",
      " 0.66%\r",
      " 0.66%\r",
      " 0.66%\r",
      " 0.67%\r",
      " 0.67%\r",
      " 0.67%\r",
      " 0.67%\r",
      " 0.67%\r",
      " 0.68%\r",
      " 0.68%\r",
      " 0.68%\r",
      " 0.68%\r",
      " 0.68%\r",
      " 0.69%\r",
      " 0.69%\r",
      " 0.69%\r",
      " 0.69%\r",
      " 0.69%\r",
      " 0.70%\r",
      " 0.70%\r",
      " 0.70%\r",
      " 0.70%\r",
      " 0.70%\r",
      " 0.71%\r",
      " 0.71%\r",
      " 0.71%\r",
      " 0.71%\r",
      " 0.71%\r",
      " 0.72%\r",
      " 0.72%\r",
      " 0.72%\r",
      " 0.72%\r",
      " 0.72%\r",
      " 0.73%\r",
      " 0.73%\r",
      " 0.73%\r",
      " 0.73%\r",
      " 0.73%\r",
      " 0.74%\r",
      " 0.74%\r",
      " 0.74%\r",
      " 0.74%\r",
      " 0.74%\r",
      " 0.75%\r",
      " 0.75%\r",
      " 0.75%\r",
      " 0.75%\r",
      " 0.75%\r",
      " 0.76%\r",
      " 0.76%\r",
      " 0.76%\r",
      " 0.76%\r",
      " 0.76%\r",
      " 0.77%\r",
      " 0.77%\r",
      " 0.77%\r",
      " 0.77%\r",
      " 0.77%\r",
      " 0.78%\r",
      " 0.78%\r",
      " 0.78%\r",
      " 0.78%\r",
      " 0.78%\r",
      " 0.79%\r",
      " 0.79%\r",
      " 0.79%\r",
      " 0.79%\r",
      " 0.79%\r",
      " 0.80%\r",
      " 0.80%\r",
      " 0.80%\r",
      " 0.80%\r",
      " 0.80%\r",
      " 0.81%\r",
      " 0.81%\r",
      " 0.81%\r",
      " 0.81%\r",
      " 0.81%\r",
      " 0.82%\r",
      " 0.82%\r",
      " 0.82%\r",
      " 0.82%\r",
      " 0.82%\r",
      " 0.83%\r",
      " 0.83%\r",
      " 0.83%\r",
      " 0.83%\r",
      " 0.83%\r",
      " 0.84%\r",
      " 0.84%\r",
      " 0.84%\r",
      " 0.84%\r",
      " 0.84%\r",
      " 0.85%\r",
      " 0.85%\r",
      " 0.85%\r",
      " 0.85%\r",
      " 0.85%\r",
      " 0.86%\r",
      " 0.86%\r",
      " 0.86%\r",
      " 0.86%\r",
      " 0.86%\r",
      " 0.87%\r",
      " 0.87%\r",
      " 0.87%\r",
      " 0.87%\r",
      " 0.87%\r",
      " 0.88%\r",
      " 0.88%\r",
      " 0.88%\r",
      " 0.88%\r",
      " 0.88%\r",
      " 0.89%\r",
      " 0.89%\r",
      " 0.89%\r",
      " 0.89%\r",
      " 0.89%\r",
      " 0.90%\r",
      " 0.90%\r",
      " 0.90%\r",
      " 0.90%\r",
      " 0.90%\r",
      " 0.91%\r",
      " 0.91%\r",
      " 0.91%\r",
      " 0.91%\r",
      " 0.91%\r",
      " 0.92%\r",
      " 0.92%\r",
      " 0.92%\r",
      " 0.92%\r",
      " 0.92%\r",
      " 0.93%\r",
      " 0.93%\r",
      " 0.93%\r",
      " 0.93%\r",
      " 0.93%\r",
      " 0.94%\r",
      " 0.94%\r",
      " 0.94%\r",
      " 0.94%\r",
      " 0.94%\r",
      " 0.95%\r",
      " 0.95%\r",
      " 0.95%\r",
      " 0.95%\r",
      " 0.95%\r",
      " 0.96%\r",
      " 0.96%\r",
      " 0.96%\r",
      " 0.96%\r",
      " 0.96%\r",
      " 0.97%\r",
      " 0.97%\r",
      " 0.97%\r",
      " 0.97%\r",
      " 0.97%\r",
      " 0.98%\r",
      " 0.98%\r",
      " 0.98%\r",
      " 0.98%\r",
      " 0.98%\r",
      " 0.99%\r",
      " 0.99%\r",
      " 0.99%\r",
      " 0.99%\r",
      " 0.99%\r",
      " 1.00%\r",
      " 1.00%\r",
      " 1.00%\r",
      " 1.00%\r",
      " 1.00%\r",
      " 1.01%\r",
      " 1.01%\r",
      " 1.01%\r",
      " 1.01%\r",
      " 1.01%\r",
      " 1.02%\r",
      " 1.02%\r",
      " 1.02%\r",
      " 1.02%\r",
      " 1.02%\r",
      " 1.03%\r",
      " 1.03%\r",
      " 1.03%\r",
      " 1.03%\r",
      " 1.03%\r",
      " 1.04%\r",
      " 1.04%\r",
      " 1.04%\r",
      " 1.04%\r",
      " 1.04%\r",
      " 1.05%\r",
      " 1.05%\r",
      " 1.05%\r",
      " 1.05%\r",
      " 1.05%\r",
      " 1.06%\r",
      " 1.06%\r",
      " 1.06%\r",
      " 1.06%\r",
      " 1.06%\r",
      " 1.07%\r",
      " 1.07%\r",
      " 1.07%\r",
      " 1.07%\r",
      " 1.07%\r",
      " 1.08%\r",
      " 1.08%\r",
      " 1.08%\r",
      " 1.08%\r",
      " 1.08%\r",
      " 1.09%\r",
      " 1.09%\r",
      " 1.09%\r",
      " 1.09%\r",
      " 1.09%\r",
      " 1.10%\r",
      " 1.10%\r",
      " 1.10%\r",
      " 1.10%\r",
      " 1.10%\r",
      " 1.11%\r",
      " 1.11%\r",
      " 1.11%\r",
      " 1.11%\r",
      " 1.11%\r",
      " 1.12%\r",
      " 1.12%\r",
      " 1.12%\r",
      " 1.12%\r",
      " 1.12%\r",
      " 1.13%\r",
      " 1.13%\r",
      " 1.13%\r",
      " 1.13%\r",
      " 1.13%\r",
      " 1.14%\r",
      " 1.14%\r",
      " 1.14%\r",
      " 1.14%\r",
      " 1.14%\r",
      " 1.15%\r",
      " 1.15%\r",
      " 1.15%\r",
      " 1.15%\r",
      " 1.15%\r",
      " 1.16%\r",
      " 1.16%\r",
      " 1.16%\r",
      " 1.16%\r",
      " 1.16%\r",
      " 1.17%\r",
      " 1.17%\r",
      " 1.17%\r",
      " 1.17%\r",
      " 1.17%\r",
      " 1.18%\r",
      " 1.18%\r",
      " 1.18%\r",
      " 1.18%\r",
      " 1.18%\r",
      " 1.19%\r",
      " 1.19%\r",
      " 1.19%\r",
      " 1.19%\r",
      " 1.19%\r",
      " 1.20%\r",
      " 1.20%\r",
      " 1.20%\r",
      " 1.20%\r",
      " 1.20%\r",
      " 1.21%\r",
      " 1.21%\r",
      " 1.21%\r",
      " 1.21%\r",
      " 1.21%\r",
      " 1.22%\r",
      " 1.22%\r",
      " 1.22%\r",
      " 1.22%\r",
      " 1.22%\r",
      " 1.23%\r",
      " 1.23%\r",
      " 1.23%\r",
      " 1.23%\r",
      " 1.23%\r",
      " 1.24%\r",
      " 1.24%\r",
      " 1.24%\r",
      " 1.24%\r",
      " 1.24%\r",
      " 1.25%\r",
      " 1.25%\r",
      " 1.25%\r",
      " 1.25%\r",
      " 1.25%\r",
      " 1.26%\r",
      " 1.26%\r",
      " 1.26%\r",
      " 1.26%\r",
      " 1.26%\r",
      " 1.27%\r",
      " 1.27%\r",
      " 1.27%\r",
      " 1.27%\r",
      " 1.27%\r",
      " 1.28%\r",
      " 1.28%\r",
      " 1.28%\r",
      " 1.28%\r",
      " 1.28%\r",
      " 1.29%\r",
      " 1.29%\r",
      " 1.29%\r",
      " 1.29%\r",
      " 1.29%\r",
      " 1.30%\r",
      " 1.30%\r",
      " 1.30%\r",
      " 1.30%\r",
      " 1.30%\r",
      " 1.31%\r",
      " 1.31%\r",
      " 1.31%\r",
      " 1.31%\r",
      " 1.31%\r",
      " 1.32%\r",
      " 1.32%\r",
      " 1.32%\r",
      " 1.32%\r",
      " 1.32%\r",
      " 1.33%\r",
      " 1.33%\r",
      " 1.33%\r",
      " 1.33%\r",
      " 1.33%\r",
      " 1.34%\r",
      " 1.34%\r",
      " 1.34%\r",
      " 1.34%\r",
      " 1.34%\r",
      " 1.35%\r",
      " 1.35%\r",
      " 1.35%\r",
      " 1.35%\r",
      " 1.35%\r",
      " 1.36%\r",
      " 1.36%\r",
      " 1.36%\r",
      " 1.36%\r",
      " 1.36%\r",
      " 1.37%\r",
      " 1.37%\r",
      " 1.37%\r",
      " 1.37%\r",
      " 1.37%\r",
      " 1.38%\r",
      " 1.38%\r",
      " 1.38%\r",
      " 1.38%\r",
      " 1.38%\r",
      " 1.39%\r",
      " 1.39%\r",
      " 1.39%\r",
      " 1.39%\r",
      " 1.39%\r",
      " 1.40%\r",
      " 1.40%\r",
      " 1.40%\r",
      " 1.40%\r",
      " 1.40%\r",
      " 1.41%\r",
      " 1.41%\r",
      " 1.41%\r",
      " 1.41%\r",
      " 1.41%\r",
      " 1.42%\r",
      " 1.42%\r",
      " 1.42%\r",
      " 1.42%\r",
      " 1.42%\r",
      " 1.43%\r",
      " 1.43%\r",
      " 1.43%\r",
      " 1.43%\r",
      " 1.43%\r",
      " 1.44%\r",
      " 1.44%\r",
      " 1.44%\r",
      " 1.44%\r",
      " 1.44%\r",
      " 1.45%\r",
      " 1.45%\r",
      " 1.45%\r",
      " 1.45%\r",
      " 1.45%\r",
      " 1.46%\r",
      " 1.46%\r",
      " 1.46%\r",
      " 1.46%\r",
      " 1.46%\r",
      " 1.47%\r",
      " 1.47%\r",
      " 1.47%\r",
      " 1.47%\r",
      " 1.47%\r",
      " 1.48%\r",
      " 1.48%\r",
      " 1.48%\r",
      " 1.48%\r",
      " 1.48%\r",
      " 1.49%\r",
      " 1.49%\r",
      " 1.49%\r",
      " 1.49%\r",
      " 1.49%\r",
      " 1.50%\r",
      " 1.50%\r",
      " 1.50%\r",
      " 1.50%\r",
      " 1.50%\r",
      " 1.51%\r",
      " 1.51%\r",
      " 1.51%\r",
      " 1.51%\r",
      " 1.51%\r",
      " 1.52%\r",
      " 1.52%\r",
      " 1.52%\r",
      " 1.52%\r",
      " 1.52%\r",
      " 1.53%\r",
      " 1.53%\r",
      " 1.53%\r",
      " 1.53%\r",
      " 1.53%\r",
      " 1.54%\r",
      " 1.54%\r",
      " 1.54%\r",
      " 1.54%\r",
      " 1.54%\r",
      " 1.55%\r",
      " 1.55%\r",
      " 1.55%\r",
      " 1.55%\r",
      " 1.55%\r",
      " 1.56%\r",
      " 1.56%\r",
      " 1.56%\r",
      " 1.56%\r",
      " 1.56%\r",
      " 1.57%\r",
      " 1.57%\r",
      " 1.57%\r",
      " 1.57%\r",
      " 1.57%\r",
      " 1.58%\r",
      " 1.58%\r",
      " 1.58%\r",
      " 1.58%\r",
      " 1.58%\r",
      " 1.59%\r",
      " 1.59%\r",
      " 1.59%\r",
      " 1.59%\r",
      " 1.59%\r",
      " 1.60%\r",
      " 1.60%\r",
      " 1.60%\r",
      " 1.60%\r",
      " 1.60%\r",
      " 1.61%\r",
      " 1.61%\r",
      " 1.61%\r",
      " 1.61%\r",
      " 1.61%\r",
      " 1.62%\r",
      " 1.62%\r",
      " 1.62%\r",
      " 1.62%\r",
      " 1.62%\r",
      " 1.63%\r",
      " 1.63%\r",
      " 1.63%\r",
      " 1.63%\r",
      " 1.63%\r",
      " 1.64%\r",
      " 1.64%\r",
      " 1.64%\r",
      " 1.64%\r",
      " 1.64%\r",
      " 1.65%\r",
      " 1.65%\r",
      " 1.65%\r",
      " 1.65%\r",
      " 1.65%\r",
      " 1.66%\r",
      " 1.66%\r",
      " 1.66%\r",
      " 1.66%\r",
      " 1.66%\r",
      " 1.67%\r",
      " 1.67%\r",
      " 1.67%\r",
      " 1.67%\r",
      " 1.67%\r",
      " 1.68%\r",
      " 1.68%\r",
      " 1.68%\r",
      " 1.68%\r",
      " 1.68%\r",
      " 1.69%\r",
      " 1.69%\r",
      " 1.69%\r",
      " 1.69%\r",
      " 1.69%\r",
      " 1.70%\r",
      " 1.70%\r",
      " 1.70%\r",
      " 1.70%\r",
      " 1.70%\r",
      " 1.71%\r",
      " 1.71%\r",
      " 1.71%\r",
      " 1.71%\r",
      " 1.71%\r",
      " 1.72%\r",
      " 1.72%\r",
      " 1.72%\r",
      " 1.72%\r",
      " 1.72%\r",
      " 1.73%\r",
      " 1.73%\r",
      " 1.73%\r",
      " 1.73%\r",
      " 1.73%\r",
      " 1.74%\r",
      " 1.74%\r",
      " 1.74%\r",
      " 1.74%\r",
      " 1.74%\r",
      " 1.75%\r",
      " 1.75%\r",
      " 1.75%\r",
      " 1.75%\r",
      " 1.75%\r",
      " 1.76%\r",
      " 1.76%\r",
      " 1.76%\r",
      " 1.76%\r",
      " 1.76%\r",
      " 1.77%\r",
      " 1.77%\r",
      " 1.77%\r",
      " 1.77%\r",
      " 1.77%\r",
      " 1.78%\r",
      " 1.78%\r",
      " 1.78%\r",
      " 1.78%\r",
      " 1.78%\r",
      " 1.79%\r",
      " 1.79%\r",
      " 1.79%\r",
      " 1.79%\r",
      " 1.79%\r",
      " 1.80%\r",
      " 1.80%\r",
      " 1.80%\r",
      " 1.80%\r",
      " 1.80%\r",
      " 1.81%\r",
      " 1.81%\r",
      " 1.81%\r",
      " 1.81%\r",
      " 1.81%\r",
      " 1.82%\r",
      " 1.82%\r",
      " 1.82%\r",
      " 1.82%\r",
      " 1.82%\r",
      " 1.83%\r",
      " 1.83%\r",
      " 1.83%\r",
      " 1.83%\r",
      " 1.83%\r",
      " 1.84%\r",
      " 1.84%\r",
      " 1.84%\r",
      " 1.84%\r",
      " 1.84%\r",
      " 1.85%\r",
      " 1.85%\r",
      " 1.85%\r",
      " 1.85%\r",
      " 1.85%\r",
      " 1.86%\r",
      " 1.86%\r",
      " 1.86%\r",
      " 1.86%\r",
      " 1.86%\r",
      " 1.87%\r",
      " 1.87%\r",
      " 1.87%\r",
      " 1.87%\r",
      " 1.87%\r",
      " 1.88%\r",
      " 1.88%\r",
      " 1.88%\r",
      " 1.88%\r",
      " 1.88%\r",
      " 1.89%\r",
      " 1.89%\r",
      " 1.89%\r",
      " 1.89%\r",
      " 1.89%\r",
      " 1.90%\r",
      " 1.90%\r",
      " 1.90%\r",
      " 1.90%\r",
      " 1.90%\r",
      " 1.91%\r",
      " 1.91%\r",
      " 1.91%\r",
      " 1.91%\r",
      " 1.91%\r",
      " 1.92%\r",
      " 1.92%\r",
      " 1.92%\r",
      " 1.92%\r",
      " 1.92%\r",
      " 1.93%\r",
      " 1.93%\r",
      " 1.93%\r",
      " 1.93%\r",
      " 1.93%\r",
      " 1.94%\r",
      " 1.94%\r",
      " 1.94%\r",
      " 1.94%\r",
      " 1.94%\r",
      " 1.95%\r",
      " 1.95%\r",
      " 1.95%\r",
      " 1.95%\r",
      " 1.95%\r",
      " 1.96%\r",
      " 1.96%\r",
      " 1.96%\r",
      " 1.96%\r",
      " 1.96%\r",
      " 1.97%\r",
      " 1.97%\r",
      " 1.97%\r",
      " 1.97%\r",
      " 1.97%\r",
      " 1.98%\r",
      " 1.98%\r",
      " 1.98%\r",
      " 1.98%\r",
      " 1.98%\r",
      " 1.99%\r",
      " 1.99%\r",
      " 1.99%\r",
      " 1.99%\r",
      " 1.99%\r",
      " 2.00%\r",
      " 2.00%\r",
      " 2.00%\r",
      " 2.00%\r",
      " 2.00%\r",
      " 2.01%\r",
      " 2.01%\r",
      " 2.01%\r",
      " 2.01%\r",
      " 2.01%\r",
      " 2.02%\r",
      " 2.02%\r",
      " 2.02%\r",
      " 2.02%\r",
      " 2.02%\r",
      " 2.03%\r",
      " 2.03%\r",
      " 2.03%\r",
      " 2.03%\r",
      " 2.03%\r",
      " 2.04%\r",
      " 2.04%\r",
      " 2.04%\r",
      " 2.04%\r",
      " 2.04%\r",
      " 2.05%\r",
      " 2.05%\r",
      " 2.05%\r",
      " 2.05%\r",
      " 2.05%\r",
      " 2.06%\r",
      " 2.06%\r",
      " 2.06%\r",
      " 2.06%\r",
      " 2.06%\r",
      " 2.07%\r",
      " 2.07%\r",
      " 2.07%\r",
      " 2.07%\r",
      " 2.07%\r",
      " 2.08%\r",
      " 2.08%\r",
      " 2.08%\r",
      " 2.08%\r",
      " 2.08%\r",
      " 2.09%\r",
      " 2.09%\r",
      " 2.09%\r",
      " 2.09%\r",
      " 2.09%\r",
      " 2.10%\r",
      " 2.10%\r",
      " 2.10%\r",
      " 2.10%\r",
      " 2.10%\r",
      " 2.11%\r",
      " 2.11%\r",
      " 2.11%\r",
      " 2.11%\r",
      " 2.11%\r",
      " 2.12%\r",
      " 2.12%\r",
      " 2.12%\r",
      " 2.12%\r",
      " 2.12%\r",
      " 2.13%\r",
      " 2.13%\r",
      " 2.13%\r",
      " 2.13%\r",
      " 2.13%\r",
      " 2.14%\r",
      " 2.14%\r",
      " 2.14%\r",
      " 2.14%\r",
      " 2.14%\r",
      " 2.15%\r",
      " 2.15%\r",
      " 2.15%\r",
      " 2.15%\r",
      " 2.15%\r",
      " 2.16%\r",
      " 2.16%\r",
      " 2.16%\r",
      " 2.16%\r",
      " 2.16%\r",
      " 2.17%\r",
      " 2.17%\r",
      " 2.17%\r",
      " 2.17%\r",
      " 2.17%\r",
      " 2.18%\r",
      " 2.18%\r",
      " 2.18%\r",
      " 2.18%\r",
      " 2.18%\r",
      " 2.19%\r",
      " 2.19%\r",
      " 2.19%\r",
      " 2.19%\r",
      " 2.19%\r",
      " 2.20%\r",
      " 2.20%\r",
      " 2.20%\r",
      " 2.20%\r",
      " 2.20%\r",
      " 2.21%\r",
      " 2.21%\r",
      " 2.21%\r",
      " 2.21%\r",
      " 2.21%\r",
      " 2.22%\r",
      " 2.22%\r",
      " 2.22%\r",
      " 2.22%\r",
      " 2.22%\r",
      " 2.23%\r",
      " 2.23%\r",
      " 2.23%\r",
      " 2.23%\r",
      " 2.23%\r",
      " 2.24%\r",
      " 2.24%\r",
      " 2.24%\r",
      " 2.24%\r",
      " 2.24%\r",
      " 2.25%\r",
      " 2.25%\r",
      " 2.25%\r",
      " 2.25%\r",
      " 2.25%\r",
      " 2.26%\r",
      " 2.26%\r",
      " 2.26%\r",
      " 2.26%\r",
      " 2.26%\r",
      " 2.27%\r",
      " 2.27%\r",
      " 2.27%\r",
      " 2.27%\r",
      " 2.27%\r",
      " 2.28%\r",
      " 2.28%\r",
      " 2.28%\r",
      " 2.28%\r",
      " 2.28%\r",
      " 2.29%\r",
      " 2.29%\r",
      " 2.29%\r",
      " 2.29%\r",
      " 2.29%\r",
      " 2.30%\r",
      " 2.30%\r",
      " 2.30%\r",
      " 2.30%\r",
      " 2.30%\r",
      " 2.31%\r",
      " 2.31%\r",
      " 2.31%\r",
      " 2.31%\r",
      " 2.31%\r",
      " 2.32%\r",
      " 2.32%\r",
      " 2.32%\r",
      " 2.32%\r",
      " 2.32%\r",
      " 2.33%\r",
      " 2.33%\r",
      " 2.33%\r",
      " 2.33%\r",
      " 2.33%\r",
      " 2.34%\r",
      " 2.34%\r",
      " 2.34%\r",
      " 2.34%\r",
      " 2.34%\r",
      " 2.35%\r",
      " 2.35%\r",
      " 2.35%\r",
      " 2.35%\r",
      " 2.35%\r",
      " 2.36%\r",
      " 2.36%\r",
      " 2.36%\r",
      " 2.36%\r",
      " 2.36%\r",
      " 2.37%\r",
      " 2.37%\r",
      " 2.37%\r",
      " 2.37%\r",
      " 2.37%\r",
      " 2.38%\r",
      " 2.38%\r",
      " 2.38%\r",
      " 2.38%\r",
      " 2.38%\r",
      " 2.39%\r",
      " 2.39%\r",
      " 2.39%\r",
      " 2.39%\r",
      " 2.39%\r",
      " 2.40%\r",
      " 2.40%\r",
      " 2.40%\r",
      " 2.40%\r",
      " 2.40%\r",
      " 2.41%\r",
      " 2.41%\r",
      " 2.41%\r",
      " 2.41%\r",
      " 2.41%\r",
      " 2.42%\r",
      " 2.42%\r",
      " 2.42%\r",
      " 2.42%\r",
      " 2.42%\r",
      " 2.43%\r",
      " 2.43%\r",
      " 2.43%\r",
      " 2.43%\r",
      " 2.43%\r",
      " 2.44%\r",
      " 2.44%\r",
      " 2.44%\r",
      " 2.44%\r",
      " 2.44%\r",
      " 2.45%\r",
      " 2.45%\r",
      " 2.45%\r",
      " 2.45%\r",
      " 2.45%\r",
      " 2.46%\r",
      " 2.46%\r",
      " 2.46%\r",
      " 2.46%\r",
      " 2.46%\r",
      " 2.47%\r",
      " 2.47%\r",
      " 2.47%\r",
      " 2.47%\r",
      " 2.47%\r",
      " 2.48%\r",
      " 2.48%\r",
      " 2.48%\r",
      " 2.48%\r",
      " 2.48%\r",
      " 2.49%\r",
      " 2.49%\r",
      " 2.49%\r",
      " 2.49%\r",
      " 2.49%\r",
      " 2.50%\r",
      " 2.50%\r",
      " 2.50%\r",
      " 2.50%\r",
      " 2.50%\r",
      " 2.51%\r",
      " 2.51%\r",
      " 2.51%\r",
      " 2.51%\r",
      " 2.51%\r",
      " 2.52%\r",
      " 2.52%\r",
      " 2.52%\r",
      " 2.52%\r",
      " 2.52%\r",
      " 2.53%\r",
      " 2.53%\r",
      " 2.53%\r",
      " 2.53%\r",
      " 2.53%\r",
      " 2.54%\r",
      " 2.54%\r",
      " 2.54%\r",
      " 2.54%\r",
      " 2.54%\r",
      " 2.55%\r",
      " 2.55%\r",
      " 2.55%\r",
      " 2.55%\r",
      " 2.55%\r",
      " 2.56%\r",
      " 2.56%\r",
      " 2.56%\r",
      " 2.56%\r",
      " 2.56%\r",
      " 2.57%\r",
      " 2.57%\r",
      " 2.57%\r",
      " 2.57%\r",
      " 2.57%\r",
      " 2.58%\r",
      " 2.58%\r",
      " 2.58%\r",
      " 2.58%\r",
      " 2.58%\r",
      " 2.59%\r",
      " 2.59%\r",
      " 2.59%\r",
      " 2.59%\r",
      " 2.59%\r",
      " 2.60%\r",
      " 2.60%\r",
      " 2.60%\r",
      " 2.60%\r",
      " 2.60%\r",
      " 2.61%\r",
      " 2.61%\r",
      " 2.61%\r",
      " 2.61%\r",
      " 2.61%\r",
      " 2.62%\r",
      " 2.62%\r",
      " 2.62%\r",
      " 2.62%\r",
      " 2.62%\r",
      " 2.63%\r",
      " 2.63%\r",
      " 2.63%\r",
      " 2.63%\r",
      " 2.63%\r",
      " 2.64%\r",
      " 2.64%\r",
      " 2.64%\r",
      " 2.64%\r",
      " 2.64%\r",
      " 2.65%\r",
      " 2.65%\r",
      " 2.65%\r",
      " 2.65%\r",
      " 2.65%\r",
      " 2.66%\r",
      " 2.66%\r",
      " 2.66%\r",
      " 2.66%\r",
      " 2.66%\r",
      " 2.67%\r",
      " 2.67%\r",
      " 2.67%\r",
      " 2.67%\r",
      " 2.67%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 2.68%\r",
      " 2.68%\r",
      " 2.68%\r",
      " 2.68%\r",
      " 2.68%\r",
      " 2.69%\r",
      " 2.69%\r",
      " 2.69%\r",
      " 2.69%\r",
      " 2.69%\r",
      " 2.70%\r",
      " 2.70%\r",
      " 2.70%\r",
      " 2.70%\r",
      " 2.70%\r",
      " 2.71%\r",
      " 2.71%\r",
      " 2.71%\r",
      " 2.71%\r",
      " 2.71%\r",
      " 2.72%\r",
      " 2.72%\r",
      " 2.72%\r",
      " 2.72%\r",
      " 2.72%\r",
      " 2.73%\r",
      " 2.73%\r",
      " 2.73%\r",
      " 2.73%\r",
      " 2.73%\r",
      " 2.74%\r",
      " 2.74%\r",
      " 2.74%\r",
      " 2.74%\r",
      " 2.74%\r",
      " 2.75%\r",
      " 2.75%\r",
      " 2.75%\r",
      " 2.75%\r",
      " 2.75%\r",
      " 2.76%\r",
      " 2.76%\r",
      " 2.76%\r",
      " 2.76%\r",
      " 2.76%\r",
      " 2.77%\r",
      " 2.77%\r",
      " 2.77%\r",
      " 2.77%\r",
      " 2.77%\r",
      " 2.78%\r",
      " 2.78%\r",
      " 2.78%\r",
      " 2.78%\r",
      " 2.78%\r",
      " 2.79%\r",
      " 2.79%\r",
      " 2.79%\r",
      " 2.79%\r",
      " 2.79%\r",
      " 2.80%\r",
      " 2.80%\r",
      " 2.80%\r",
      " 2.80%\r",
      " 2.80%\r",
      " 2.81%\r",
      " 2.81%\r",
      " 2.81%\r",
      " 2.81%\r",
      " 2.81%\r",
      " 2.82%\r",
      " 2.82%\r",
      " 2.82%\r",
      " 2.82%\r",
      " 2.82%\r",
      " 2.83%\r",
      " 2.83%\r",
      " 2.83%\r",
      " 2.83%\r",
      " 2.83%\r",
      " 2.84%\r",
      " 2.84%\r",
      " 2.84%\r",
      " 2.84%\r",
      " 2.84%\r",
      " 2.85%\r",
      " 2.85%\r",
      " 2.85%\r",
      " 2.85%\r",
      " 2.85%\r",
      " 2.86%\r",
      " 2.86%\r",
      " 2.86%\r",
      " 2.86%\r",
      " 2.86%\r",
      " 2.87%\r",
      " 2.87%\r",
      " 2.87%\r",
      " 2.87%\r",
      " 2.87%\r",
      " 2.88%\r",
      " 2.88%\r",
      " 2.88%\r",
      " 2.88%\r",
      " 2.88%\r",
      " 2.89%\r",
      " 2.89%\r",
      " 2.89%\r",
      " 2.89%\r",
      " 2.89%\r",
      " 2.90%\r",
      " 2.90%\r",
      " 2.90%\r",
      " 2.90%\r",
      " 2.90%\r",
      " 2.91%\r",
      " 2.91%\r",
      " 2.91%\r",
      " 2.91%\r",
      " 2.91%\r",
      " 2.92%\r",
      " 2.92%\r",
      " 2.92%\r",
      " 2.92%\r",
      " 2.92%\r",
      " 2.93%\r",
      " 2.93%\r",
      " 2.93%\r",
      " 2.93%\r",
      " 2.93%\r",
      " 2.94%\r",
      " 2.94%\r",
      " 2.94%\r",
      " 2.94%\r",
      " 2.94%\r",
      " 2.95%\r",
      " 2.95%\r",
      " 2.95%\r",
      " 2.95%\r",
      " 2.95%\r",
      " 2.96%\r",
      " 2.96%\r",
      " 2.96%\r",
      " 2.96%\r",
      " 2.96%\r",
      " 2.97%\r",
      " 2.97%\r",
      " 2.97%\r",
      " 2.97%\r",
      " 2.97%\r",
      " 2.98%\r",
      " 2.98%\r",
      " 2.98%\r",
      " 2.98%\r",
      " 2.98%\r",
      " 2.99%\r",
      " 2.99%\r",
      " 2.99%\r",
      " 2.99%\r",
      " 2.99%\r",
      " 3.00%\r",
      " 3.00%\r",
      " 3.00%\r",
      " 3.00%\r",
      " 3.00%\r",
      " 3.01%\r",
      " 3.01%\r",
      " 3.01%\r",
      " 3.01%\r",
      " 3.01%\r",
      " 3.02%\r",
      " 3.02%\r",
      " 3.02%\r",
      " 3.02%\r",
      " 3.02%\r",
      " 3.03%\r",
      " 3.03%\r",
      " 3.03%\r",
      " 3.03%\r",
      " 3.03%\r",
      " 3.04%\r",
      " 3.04%\r",
      " 3.04%\r",
      " 3.04%\r",
      " 3.04%\r",
      " 3.05%\r",
      " 3.05%\r",
      " 3.05%\r",
      " 3.05%\r",
      " 3.05%\r",
      " 3.06%\r",
      " 3.06%\r",
      " 3.06%\r",
      " 3.06%\r",
      " 3.06%\r",
      " 3.07%\r",
      " 3.07%\r",
      " 3.07%\r",
      " 3.07%\r",
      " 3.07%\r",
      " 3.08%\r",
      " 3.08%\r",
      " 3.08%\r",
      " 3.08%\r",
      " 3.08%\r",
      " 3.09%\r",
      " 3.09%\r",
      " 3.09%\r",
      " 3.09%\r",
      " 3.09%\r",
      " 3.10%\r",
      " 3.10%\r",
      " 3.10%\r",
      " 3.10%\r",
      " 3.10%\r",
      " 3.11%\r",
      " 3.11%\r",
      " 3.11%\r",
      " 3.11%\r",
      " 3.11%\r",
      " 3.12%\r",
      " 3.12%\r",
      " 3.12%\r",
      " 3.12%\r",
      " 3.12%\r",
      " 3.13%\r",
      " 3.13%\r",
      " 3.13%\r",
      " 3.13%\r",
      " 3.13%\r",
      " 3.14%\r",
      " 3.14%\r",
      " 3.14%\r",
      " 3.14%\r",
      " 3.14%\r",
      " 3.15%\r",
      " 3.15%\r",
      " 3.15%\r",
      " 3.15%\r",
      " 3.15%\r",
      " 3.16%\r",
      " 3.16%\r",
      " 3.16%\r",
      " 3.16%\r",
      " 3.16%\r",
      " 3.17%\r",
      " 3.17%\r",
      " 3.17%\r",
      " 3.17%\r",
      " 3.17%\r",
      " 3.18%\r",
      " 3.18%\r",
      " 3.18%\r",
      " 3.18%\r",
      " 3.18%\r",
      " 3.19%\r",
      " 3.19%\r",
      " 3.19%\r",
      " 3.19%\r",
      " 3.19%\r",
      " 3.20%\r",
      " 3.20%\r",
      " 3.20%\r",
      " 3.20%\r",
      " 3.20%\r",
      " 3.21%\r",
      " 3.21%\r",
      " 3.21%\r",
      " 3.21%\r",
      " 3.21%\r",
      " 3.22%\r",
      " 3.22%\r",
      " 3.22%\r",
      " 3.22%\r",
      " 3.22%\r",
      " 3.23%\r",
      " 3.23%\r",
      " 3.23%\r",
      " 3.23%\r",
      " 3.23%\r",
      " 3.24%\r",
      " 3.24%\r",
      " 3.24%\r",
      " 3.24%\r",
      " 3.24%\r",
      " 3.25%\r",
      " 3.25%\r",
      " 3.25%\r",
      " 3.25%\r",
      " 3.25%\r",
      " 3.26%\r",
      " 3.26%\r",
      " 3.26%\r",
      " 3.26%\r",
      " 3.26%\r",
      " 3.27%\r",
      " 3.27%\r",
      " 3.27%\r",
      " 3.27%\r",
      " 3.27%\r",
      " 3.28%\r",
      " 3.28%\r",
      " 3.28%\r",
      " 3.28%\r",
      " 3.28%\r",
      " 3.29%\r",
      " 3.29%\r",
      " 3.29%\r",
      " 3.29%\r",
      " 3.29%\r",
      " 3.30%\r",
      " 3.30%\r",
      " 3.30%\r",
      " 3.30%\r",
      " 3.30%\r",
      " 3.31%\r",
      " 3.31%\r",
      " 3.31%\r",
      " 3.31%\r",
      " 3.31%\r",
      " 3.32%\r",
      " 3.32%\r",
      " 3.32%\r",
      " 3.32%\r",
      " 3.32%\r",
      " 3.33%\r",
      " 3.33%\r",
      " 3.33%\r",
      " 3.33%\r",
      " 3.33%\r",
      " 3.34%\r",
      " 3.34%\r",
      " 3.34%\r",
      " 3.34%\r",
      " 3.34%\r",
      " 3.35%\r",
      " 3.35%\r",
      " 3.35%\r",
      " 3.35%\r",
      " 3.35%\r",
      " 3.36%\r",
      " 3.36%\r",
      " 3.36%\r",
      " 3.36%\r",
      " 3.36%\r",
      " 3.37%\r",
      " 3.37%\r",
      " 3.37%\r",
      " 3.37%\r",
      " 3.37%\r",
      " 3.38%\r",
      " 3.38%\r",
      " 3.38%\r",
      " 3.38%\r",
      " 3.38%\r",
      " 3.39%\r",
      " 3.39%\r",
      " 3.39%\r",
      " 3.39%\r",
      " 3.39%\r",
      " 3.40%\r",
      " 3.40%\r",
      " 3.40%\r",
      " 3.40%\r",
      " 3.40%\r",
      " 3.41%\r",
      " 3.41%\r",
      " 3.41%\r",
      " 3.41%\r",
      " 3.41%\r",
      " 3.42%\r",
      " 3.42%\r",
      " 3.42%\r",
      " 3.42%\r",
      " 3.42%\r",
      " 3.43%\r",
      " 3.43%\r",
      " 3.43%\r",
      " 3.43%\r",
      " 3.43%\r",
      " 3.44%\r",
      " 3.44%\r",
      " 3.44%\r",
      " 3.44%\r",
      " 3.44%\r",
      " 3.45%\r",
      " 3.45%\r",
      " 3.45%\r",
      " 3.45%\r",
      " 3.45%\r",
      " 3.46%\r",
      " 3.46%\r",
      " 3.46%\r",
      " 3.46%\r",
      " 3.46%\r",
      " 3.47%\r",
      " 3.47%\r",
      " 3.47%\r",
      " 3.47%\r",
      " 3.47%\r",
      " 3.48%\r",
      " 3.48%\r",
      " 3.48%\r",
      " 3.48%\r",
      " 3.48%\r",
      " 3.49%\r",
      " 3.49%\r",
      " 3.49%\r",
      " 3.49%\r",
      " 3.49%\r",
      " 3.50%\r",
      " 3.50%\r",
      " 3.50%\r",
      " 3.50%\r",
      " 3.50%\r",
      " 3.51%\r",
      " 3.51%\r",
      " 3.51%\r",
      " 3.51%\r",
      " 3.51%\r",
      " 3.52%\r",
      " 3.52%\r",
      " 3.52%\r",
      " 3.52%\r",
      " 3.52%\r",
      " 3.53%\r",
      " 3.53%\r",
      " 3.53%\r",
      " 3.53%\r",
      " 3.53%\r",
      " 3.54%\r",
      " 3.54%\r",
      " 3.54%\r",
      " 3.54%\r",
      " 3.54%\r",
      " 3.55%\r",
      " 3.55%\r",
      " 3.55%\r",
      " 3.55%\r",
      " 3.55%\r",
      " 3.56%\r",
      " 3.56%\r",
      " 3.56%\r",
      " 3.56%\r",
      " 3.56%\r",
      " 3.57%\r",
      " 3.57%\r",
      " 3.57%\r",
      " 3.57%\r",
      " 3.57%\r",
      " 3.58%\r",
      " 3.58%\r",
      " 3.58%\r",
      " 3.58%\r",
      " 3.58%\r",
      " 3.59%\r",
      " 3.59%\r",
      " 3.59%\r",
      " 3.59%\r",
      " 3.59%\r",
      " 3.60%\r",
      " 3.60%\r",
      " 3.60%\r",
      " 3.60%\r",
      " 3.60%\r",
      " 3.61%\r",
      " 3.61%\r",
      " 3.61%\r",
      " 3.61%\r",
      " 3.61%\r",
      " 3.62%\r",
      " 3.62%\r",
      " 3.62%\r",
      " 3.62%\r",
      " 3.62%\r",
      " 3.63%\r",
      " 3.63%\r",
      " 3.63%\r",
      " 3.63%\r",
      " 3.63%\r",
      " 3.64%\r",
      " 3.64%\r",
      " 3.64%\r",
      " 3.64%\r",
      " 3.64%\r",
      " 3.65%\r",
      " 3.65%\r",
      " 3.65%\r",
      " 3.65%\r",
      " 3.65%\r",
      " 3.66%\r",
      " 3.66%\r",
      " 3.66%\r",
      " 3.66%\r",
      " 3.66%\r",
      " 3.67%\r",
      " 3.67%\r",
      " 3.67%\r",
      " 3.67%\r",
      " 3.67%\r",
      " 3.68%\r",
      " 3.68%\r",
      " 3.68%\r",
      " 3.68%\r",
      " 3.68%\r",
      " 3.69%\r",
      " 3.69%\r",
      " 3.69%\r",
      " 3.69%\r",
      " 3.69%\r",
      " 3.70%\r",
      " 3.70%\r",
      " 3.70%\r",
      " 3.70%\r",
      " 3.70%\r",
      " 3.71%\r",
      " 3.71%\r",
      " 3.71%\r",
      " 3.71%\r",
      " 3.71%\r",
      " 3.72%\r",
      " 3.72%\r",
      " 3.72%\r",
      " 3.72%\r",
      " 3.72%\r",
      " 3.73%\r",
      " 3.73%\r",
      " 3.73%\r",
      " 3.73%\r",
      " 3.73%\r",
      " 3.74%\r",
      " 3.74%\r",
      " 3.74%\r",
      " 3.74%\r",
      " 3.74%\r",
      " 3.75%\r",
      " 3.75%\r",
      " 3.75%\r",
      " 3.75%\r",
      " 3.75%\r",
      " 3.76%\r",
      " 3.76%\r",
      " 3.76%\r",
      " 3.76%\r",
      " 3.76%\r",
      " 3.77%\r",
      " 3.77%\r",
      " 3.77%\r",
      " 3.77%\r",
      " 3.77%\r",
      " 3.78%\r",
      " 3.78%\r",
      " 3.78%\r",
      " 3.78%\r",
      " 3.78%\r",
      " 3.79%\r",
      " 3.79%\r",
      " 3.79%\r",
      " 3.79%\r",
      " 3.79%\r",
      " 3.80%\r",
      " 3.80%\r",
      " 3.80%\r",
      " 3.80%\r",
      " 3.80%\r",
      " 3.81%\r",
      " 3.81%\r",
      " 3.81%\r",
      " 3.81%\r",
      " 3.81%\r",
      " 3.82%\r",
      " 3.82%\r",
      " 3.82%\r",
      " 3.82%\r",
      " 3.82%\r",
      " 3.83%\r",
      " 3.83%\r",
      " 3.83%\r",
      " 3.83%\r",
      " 3.83%\r",
      " 3.84%\r",
      " 3.84%\r",
      " 3.84%\r",
      " 3.84%\r",
      " 3.84%\r",
      " 3.85%\r",
      " 3.85%\r",
      " 3.85%\r",
      " 3.85%\r",
      " 3.85%\r",
      " 3.86%\r",
      " 3.86%\r",
      " 3.86%\r",
      " 3.86%\r",
      " 3.86%\r",
      " 3.87%\r",
      " 3.87%\r",
      " 3.87%\r",
      " 3.87%\r",
      " 3.87%\r",
      " 3.88%\r",
      " 3.88%\r",
      " 3.88%\r",
      " 3.88%\r",
      " 3.88%\r",
      " 3.89%\r",
      " 3.89%\r",
      " 3.89%\r",
      " 3.89%\r",
      " 3.89%\r",
      " 3.90%\r",
      " 3.90%\r",
      " 3.90%\r",
      " 3.90%\r",
      " 3.90%\r",
      " 3.91%\r",
      " 3.91%\r",
      " 3.91%\r",
      " 3.91%\r",
      " 3.91%\r",
      " 3.92%\r",
      " 3.92%\r",
      " 3.92%\r",
      " 3.92%\r",
      " 3.92%\r",
      " 3.93%\r",
      " 3.93%\r",
      " 3.93%\r",
      " 3.93%\r",
      " 3.93%\r",
      " 3.94%\r",
      " 3.94%\r",
      " 3.94%\r",
      " 3.94%\r",
      " 3.94%\r",
      " 3.95%\r",
      " 3.95%\r",
      " 3.95%\r",
      " 3.95%\r",
      " 3.95%\r",
      " 3.96%\r",
      " 3.96%\r",
      " 3.96%\r",
      " 3.96%\r",
      " 3.96%\r",
      " 3.97%\r",
      " 3.97%\r",
      " 3.97%\r",
      " 3.97%\r",
      " 3.97%\r",
      " 3.98%\r",
      " 3.98%\r",
      " 3.98%\r",
      " 3.98%\r",
      " 3.98%\r",
      " 3.99%\r",
      " 3.99%\r",
      " 3.99%\r",
      " 3.99%\r",
      " 3.99%\r",
      " 4.00%\r",
      " 4.00%\r",
      " 4.00%\r",
      " 4.00%\r",
      " 4.00%\r",
      " 4.01%\r",
      " 4.01%\r",
      " 4.01%\r",
      " 4.01%\r",
      " 4.01%\r",
      " 4.02%\r",
      " 4.02%\r",
      " 4.02%\r",
      " 4.02%\r",
      " 4.02%\r",
      " 4.03%\r",
      " 4.03%\r",
      " 4.03%\r",
      " 4.03%\r",
      " 4.03%\r",
      " 4.04%\r",
      " 4.04%\r",
      " 4.04%\r",
      " 4.04%\r",
      " 4.04%\r",
      " 4.05%\r",
      " 4.05%\r",
      " 4.05%\r",
      " 4.05%\r",
      " 4.05%\r",
      " 4.06%\r",
      " 4.06%\r",
      " 4.06%\r",
      " 4.06%\r",
      " 4.06%\r",
      " 4.07%\r",
      " 4.07%\r",
      " 4.07%\r",
      " 4.07%\r",
      " 4.07%\r",
      " 4.08%\r",
      " 4.08%\r",
      " 4.08%\r",
      " 4.08%\r",
      " 4.08%\r",
      " 4.09%\r",
      " 4.09%\r",
      " 4.09%\r",
      " 4.09%\r",
      " 4.09%\r",
      " 4.10%\r",
      " 4.10%\r",
      " 4.10%\r",
      " 4.10%\r",
      " 4.10%\r",
      " 4.11%\r",
      " 4.11%\r",
      " 4.11%\r",
      " 4.11%\r",
      " 4.11%\r",
      " 4.12%\r",
      " 4.12%\r",
      " 4.12%\r",
      " 4.12%\r",
      " 4.12%\r",
      " 4.13%\r",
      " 4.13%\r",
      " 4.13%\r",
      " 4.13%\r",
      " 4.13%\r",
      " 4.14%\r",
      " 4.14%\r",
      " 4.14%\r",
      " 4.14%\r",
      " 4.14%\r",
      " 4.15%\r",
      " 4.15%\r",
      " 4.15%\r",
      " 4.15%\r",
      " 4.15%\r",
      " 4.16%\r",
      " 4.16%\r",
      " 4.16%\r",
      " 4.16%\r",
      " 4.16%\r",
      " 4.17%\r",
      " 4.17%\r",
      " 4.17%\r",
      " 4.17%\r",
      " 4.17%\r",
      " 4.18%\r",
      " 4.18%\r",
      " 4.18%\r",
      " 4.18%\r",
      " 4.18%\r",
      " 4.19%\r",
      " 4.19%\r",
      " 4.19%\r",
      " 4.19%\r",
      " 4.19%\r",
      " 4.20%\r",
      " 4.20%\r",
      " 4.20%\r",
      " 4.20%\r",
      " 4.20%\r",
      " 4.21%\r",
      " 4.21%\r",
      " 4.21%\r",
      " 4.21%\r",
      " 4.21%\r",
      " 4.22%\r",
      " 4.22%\r",
      " 4.22%\r",
      " 4.22%\r",
      " 4.22%\r",
      " 4.23%\r",
      " 4.23%\r",
      " 4.23%\r",
      " 4.23%\r",
      " 4.23%\r",
      " 4.24%\r",
      " 4.24%\r",
      " 4.24%\r",
      " 4.24%\r",
      " 4.24%\r",
      " 4.25%\r",
      " 4.25%\r",
      " 4.25%\r",
      " 4.25%\r",
      " 4.25%\r",
      " 4.26%\r",
      " 4.26%\r",
      " 4.26%\r",
      " 4.26%\r",
      " 4.26%\r",
      " 4.27%\r",
      " 4.27%\r",
      " 4.27%\r",
      " 4.27%\r",
      " 4.27%\r",
      " 4.28%\r",
      " 4.28%\r",
      " 4.28%\r",
      " 4.28%\r",
      " 4.28%\r",
      " 4.29%\r",
      " 4.29%\r",
      " 4.29%\r",
      " 4.29%\r",
      " 4.29%\r",
      " 4.30%\r",
      " 4.30%\r",
      " 4.30%\r",
      " 4.30%\r",
      " 4.30%\r",
      " 4.31%\r",
      " 4.31%\r",
      " 4.31%\r",
      " 4.31%\r",
      " 4.31%\r",
      " 4.32%\r",
      " 4.32%\r",
      " 4.32%\r",
      " 4.32%\r",
      " 4.32%\r",
      " 4.33%\r",
      " 4.33%\r",
      " 4.33%\r",
      " 4.33%\r",
      " 4.33%\r",
      " 4.34%\r",
      " 4.34%\r",
      " 4.34%\r",
      " 4.34%\r",
      " 4.34%\r",
      " 4.35%\r",
      " 4.35%\r",
      " 4.35%\r",
      " 4.35%\r",
      " 4.35%\r",
      " 4.36%\r",
      " 4.36%\r",
      " 4.36%\r",
      " 4.36%\r",
      " 4.36%\r",
      " 4.37%\r",
      " 4.37%\r",
      " 4.37%\r",
      " 4.37%\r",
      " 4.37%\r",
      " 4.38%\r",
      " 4.38%\r",
      " 4.38%\r",
      " 4.38%\r",
      " 4.38%\r",
      " 4.39%\r",
      " 4.39%\r",
      " 4.39%\r",
      " 4.39%\r",
      " 4.39%\r",
      " 4.40%\r",
      " 4.40%\r",
      " 4.40%\r",
      " 4.40%\r",
      " 4.40%\r",
      " 4.41%\r",
      " 4.41%\r",
      " 4.41%\r",
      " 4.41%\r",
      " 4.41%\r",
      " 4.42%\r",
      " 4.42%\r",
      " 4.42%\r",
      " 4.42%\r",
      " 4.42%\r",
      " 4.43%\r",
      " 4.43%\r",
      " 4.43%\r",
      " 4.43%\r",
      " 4.43%\r",
      " 4.44%\r",
      " 4.44%\r",
      " 4.44%\r",
      " 4.44%\r",
      " 4.44%\r",
      " 4.45%\r",
      " 4.45%\r",
      " 4.45%\r",
      " 4.45%\r",
      " 4.45%\r",
      " 4.46%\r",
      " 4.46%\r",
      " 4.46%\r",
      " 4.46%\r",
      " 4.46%\r",
      " 4.47%\r",
      " 4.47%\r",
      " 4.47%\r",
      " 4.47%\r",
      " 4.47%\r",
      " 4.48%\r",
      " 4.48%\r",
      " 4.48%\r",
      " 4.48%\r",
      " 4.48%\r",
      " 4.49%\r",
      " 4.49%\r",
      " 4.49%\r",
      " 4.49%\r",
      " 4.49%\r",
      " 4.50%\r",
      " 4.50%\r",
      " 4.50%\r",
      " 4.50%\r",
      " 4.50%\r",
      " 4.51%\r",
      " 4.51%\r",
      " 4.51%\r",
      " 4.51%\r",
      " 4.51%\r",
      " 4.52%\r",
      " 4.52%\r",
      " 4.52%\r",
      " 4.52%\r",
      " 4.52%\r",
      " 4.53%\r",
      " 4.53%\r",
      " 4.53%\r",
      " 4.53%\r",
      " 4.53%\r",
      " 4.54%\r",
      " 4.54%\r",
      " 4.54%\r",
      " 4.54%\r",
      " 4.54%\r",
      " 4.55%\r",
      " 4.55%\r",
      " 4.55%\r",
      " 4.55%\r",
      " 4.55%\r",
      " 4.56%\r",
      " 4.56%\r",
      " 4.56%\r",
      " 4.56%\r",
      " 4.56%\r",
      " 4.57%\r",
      " 4.57%\r",
      " 4.57%\r",
      " 4.57%\r",
      " 4.57%\r",
      " 4.58%\r",
      " 4.58%\r",
      " 4.58%\r",
      " 4.58%\r",
      " 4.58%\r",
      " 4.59%\r",
      " 4.59%\r",
      " 4.59%\r",
      " 4.59%\r",
      " 4.59%\r",
      " 4.60%\r",
      " 4.60%\r",
      " 4.60%\r",
      " 4.60%\r",
      " 4.60%\r",
      " 4.61%\r",
      " 4.61%\r",
      " 4.61%\r",
      " 4.61%\r",
      " 4.61%\r",
      " 4.62%\r",
      " 4.62%\r",
      " 4.62%\r",
      " 4.62%\r",
      " 4.62%\r",
      " 4.63%\r",
      " 4.63%\r",
      " 4.63%\r",
      " 4.63%\r",
      " 4.63%\r",
      " 4.64%\r",
      " 4.64%\r",
      " 4.64%\r",
      " 4.64%\r",
      " 4.64%\r",
      " 4.65%\r",
      " 4.65%\r",
      " 4.65%\r",
      " 4.65%\r",
      " 4.65%\r",
      " 4.66%\r",
      " 4.66%\r",
      " 4.66%\r",
      " 4.66%\r",
      " 4.66%\r",
      " 4.67%\r",
      " 4.67%\r",
      " 4.67%\r",
      " 4.67%\r",
      " 4.67%\r",
      " 4.68%\r",
      " 4.68%\r",
      " 4.68%\r",
      " 4.68%\r",
      " 4.68%\r",
      " 4.69%\r",
      " 4.69%\r",
      " 4.69%\r",
      " 4.69%\r",
      " 4.69%\r",
      " 4.70%\r",
      " 4.70%\r",
      " 4.70%\r",
      " 4.70%\r",
      " 4.70%\r",
      " 4.71%\r",
      " 4.71%\r",
      " 4.71%\r",
      " 4.71%\r",
      " 4.71%\r",
      " 4.72%\r",
      " 4.72%\r",
      " 4.72%\r",
      " 4.72%\r",
      " 4.72%\r",
      " 4.73%\r",
      " 4.73%\r",
      " 4.73%\r",
      " 4.73%\r",
      " 4.73%\r",
      " 4.74%\r",
      " 4.74%\r",
      " 4.74%\r",
      " 4.74%\r",
      " 4.74%\r",
      " 4.75%\r",
      " 4.75%\r",
      " 4.75%\r",
      " 4.75%\r",
      " 4.75%\r",
      " 4.76%\r",
      " 4.76%\r",
      " 4.76%\r",
      " 4.76%\r",
      " 4.76%\r",
      " 4.77%\r",
      " 4.77%\r",
      " 4.77%\r",
      " 4.77%\r",
      " 4.77%\r",
      " 4.78%\r",
      " 4.78%\r",
      " 4.78%\r",
      " 4.78%\r",
      " 4.78%\r",
      " 4.79%\r",
      " 4.79%\r",
      " 4.79%\r",
      " 4.79%\r",
      " 4.79%\r",
      " 4.80%\r",
      " 4.80%\r",
      " 4.80%\r",
      " 4.80%\r",
      " 4.80%\r",
      " 4.81%\r",
      " 4.81%\r",
      " 4.81%\r",
      " 4.81%\r",
      " 4.81%\r",
      " 4.82%\r",
      " 4.82%\r",
      " 4.82%\r",
      " 4.82%\r",
      " 4.82%\r",
      " 4.83%\r",
      " 4.83%\r",
      " 4.83%\r",
      " 4.83%\r",
      " 4.83%\r",
      " 4.84%\r",
      " 4.84%\r",
      " 4.84%\r",
      " 4.84%\r",
      " 4.84%\r",
      " 4.85%\r",
      " 4.85%\r",
      " 4.85%\r",
      " 4.85%\r",
      " 4.85%\r",
      " 4.86%\r",
      " 4.86%\r",
      " 4.86%\r",
      " 4.86%\r",
      " 4.86%\r",
      " 4.87%\r",
      " 4.87%\r",
      " 4.87%\r",
      " 4.87%\r",
      " 4.87%\r",
      " 4.88%\r",
      " 4.88%\r",
      " 4.88%\r",
      " 4.88%\r",
      " 4.88%\r",
      " 4.89%\r",
      " 4.89%\r",
      " 4.89%\r",
      " 4.89%\r",
      " 4.89%\r",
      " 4.90%\r",
      " 4.90%\r",
      " 4.90%\r",
      " 4.90%\r",
      " 4.90%\r",
      " 4.91%\r",
      " 4.91%\r",
      " 4.91%\r",
      " 4.91%\r",
      " 4.91%\r",
      " 4.92%\r",
      " 4.92%\r",
      " 4.92%\r",
      " 4.92%\r",
      " 4.92%\r",
      " 4.93%\r",
      " 4.93%\r",
      " 4.93%\r",
      " 4.93%\r",
      " 4.93%\r",
      " 4.94%\r",
      " 4.94%\r",
      " 4.94%\r",
      " 4.94%\r",
      " 4.94%\r",
      " 4.95%\r",
      " 4.95%\r",
      " 4.95%\r",
      " 4.95%\r",
      " 4.95%\r",
      " 4.96%\r",
      " 4.96%\r",
      " 4.96%\r",
      " 4.96%\r",
      " 4.96%\r",
      " 4.97%\r",
      " 4.97%\r",
      " 4.97%\r",
      " 4.97%\r",
      " 4.97%\r",
      " 4.98%\r",
      " 4.98%\r",
      " 4.98%\r",
      " 4.98%\r",
      " 4.98%\r",
      " 4.99%\r",
      " 4.99%\r",
      " 4.99%\r",
      " 4.99%\r",
      " 4.99%\r",
      " 5.00%\r",
      " 5.00%\r",
      " 5.00%\r",
      " 5.00%\r",
      " 5.00%\r",
      " 5.01%\r",
      " 5.01%\r",
      " 5.01%\r",
      " 5.01%\r",
      " 5.01%\r",
      " 5.02%\r",
      " 5.02%\r",
      " 5.02%\r",
      " 5.02%\r",
      " 5.02%\r",
      " 5.03%\r",
      " 5.03%\r",
      " 5.03%\r",
      " 5.03%\r",
      " 5.03%\r",
      " 5.04%\r",
      " 5.04%\r",
      " 5.04%\r",
      " 5.04%\r",
      " 5.04%\r",
      " 5.05%\r",
      " 5.05%\r",
      " 5.05%\r",
      " 5.05%\r",
      " 5.05%\r",
      " 5.06%\r",
      " 5.06%\r",
      " 5.06%\r",
      " 5.06%\r",
      " 5.06%\r",
      " 5.07%\r",
      " 5.07%\r",
      " 5.07%\r",
      " 5.07%\r",
      " 5.07%\r",
      " 5.08%\r",
      " 5.08%\r",
      " 5.08%\r",
      " 5.08%\r",
      " 5.08%\r",
      " 5.09%\r",
      " 5.09%\r",
      " 5.09%\r",
      " 5.09%\r",
      " 5.09%\r",
      " 5.10%\r",
      " 5.10%\r",
      " 5.10%\r",
      " 5.10%\r",
      " 5.10%\r",
      " 5.11%\r",
      " 5.11%\r",
      " 5.11%\r",
      " 5.11%\r",
      " 5.11%\r",
      " 5.12%\r",
      " 5.12%\r",
      " 5.12%\r",
      " 5.12%\r",
      " 5.12%\r",
      " 5.13%\r",
      " 5.13%\r",
      " 5.13%\r",
      " 5.13%\r",
      " 5.13%\r",
      " 5.14%\r",
      " 5.14%\r",
      " 5.14%\r",
      " 5.14%\r",
      " 5.14%\r",
      " 5.15%\r",
      " 5.15%\r",
      " 5.15%\r",
      " 5.15%\r",
      " 5.15%\r",
      " 5.16%\r",
      " 5.16%\r",
      " 5.16%\r",
      " 5.16%\r",
      " 5.16%\r",
      " 5.17%\r",
      " 5.17%\r",
      " 5.17%\r",
      " 5.17%\r",
      " 5.17%\r",
      " 5.18%\r",
      " 5.18%\r",
      " 5.18%\r",
      " 5.18%\r",
      " 5.18%\r",
      " 5.19%\r",
      " 5.19%\r",
      " 5.19%\r",
      " 5.19%\r",
      " 5.19%\r",
      " 5.20%\r",
      " 5.20%\r",
      " 5.20%\r",
      " 5.20%\r",
      " 5.20%\r",
      " 5.21%\r",
      " 5.21%\r",
      " 5.21%\r",
      " 5.21%\r",
      " 5.21%\r",
      " 5.22%\r",
      " 5.22%\r",
      " 5.22%\r",
      " 5.22%\r",
      " 5.22%\r",
      " 5.23%\r",
      " 5.23%\r",
      " 5.23%\r",
      " 5.23%\r",
      " 5.23%\r",
      " 5.24%\r",
      " 5.24%\r",
      " 5.24%\r",
      " 5.24%\r",
      " 5.24%\r",
      " 5.25%\r",
      " 5.25%\r",
      " 5.25%\r",
      " 5.25%\r",
      " 5.25%\r",
      " 5.26%\r",
      " 5.26%\r",
      " 5.26%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "labels    = []\n",
    "lenghts   = []\n",
    "\n",
    "doc_stream = stream_docs('shuffled_movie_data.csv')\n",
    "\n",
    "for idx, review in enumerate(doc_stream):\n",
    "    list_of_words = tokenizer(review[0])\n",
    "    sentences.append(list_of_words)\n",
    "    labels.append(review[1])\n",
    "    lenghts.append(len(list_of_words))\n",
    "    sys.stdout.write('\\r{:5.2f}%'.format(100*(idx+1)/50000))\n",
    "sys.stdout.write('\\rDone     \\n\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximun number of words in a review : 2507\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = max(lenghts)\n",
    "print('Maximun number of words in a review :', MAXLEN)\n",
    "\n",
    "assert len(sentences) == len(labels) == 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN LEN =  236\n"
     ]
    }
   ],
   "source": [
    "MEAN_LEN = int(sum(lenghts)/len(lenghts))\n",
    "print('MEAN LEN = ', MEAN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def bag_words(reviews, vocabulary):\n",
    "    all_words = []\n",
    "    for review in reviews:\n",
    "        all_words += review\n",
    "    \n",
    "    count  = [('UNKNOWN', -1)]\n",
    "    count += Counter(all_words).most_common(vocabulary - 1)\n",
    "    \n",
    "    word_dict = {}\n",
    "    for i in range(len(count)):\n",
    "        word_dict[count[i][0]] = i\n",
    "    \n",
    "    return word_dict, dict(zip(word_dict.values(), word_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index, id_toWord = bag_words(sentences, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_index_sentences(reviews, dictionary, MEAN_LEN):\n",
    "    ID_sentences = [] \n",
    "    for review in reviews:\n",
    "        ID_sentence = [0 for i in range(MEAN_LEN)]\n",
    "        for lsen, word in enumerate(review):\n",
    "            idr = dictionary.get(word, 0)\n",
    "            if lsen >= MEAN_LEN: break\n",
    "            else: ID_sentence[lsen] = idr\n",
    "        ID_sentences.append(ID_sentence)\n",
    "    return ID_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDreviews = make_index_sentences(sentences, word_index, MEAN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: define features based on word embeddings (pre-trained word2vec / Glove/Fastext emebddings can be used)\n",
    "# Define suitable d dimension, and sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding based on Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_input_file = 'models/glove.6B.100d.txt'\n",
    "word2vec_output_file = 'models/glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "filename = 'models/glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698541283607483)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'woman' is similar to 'girl' with a score of 0.8473\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['woman'], topn=1)\n",
    "print(\"'woman' is similar to '{}' with a score of {:1.4f}\".format(result[0][0],result[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size : 400000\n"
     ]
    }
   ],
   "source": [
    "VOC_SIZE = len(model.vocab.keys())\n",
    "print('vocabulary size :', VOC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  100\n"
     ]
    }
   ],
   "source": [
    "EMB_SIZE = model['woman'].size\n",
    "print('embedding size : ', EMB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewVectorizer:\n",
    "    def __init__(self, model, maxlen, emb_size):\n",
    "        self.model    = model\n",
    "        self.maxlen   = maxlen\n",
    "        self.emb_size = emb_size\n",
    "    def transform(self, reviews_tokenized):\n",
    "        n = len(reviews_tokenized)\n",
    "        vector = np.zeros((n, self.maxlen, self.emb_size), dtype = np.float32)\n",
    "        for idx, review in enumerate(reviews_tokenized):\n",
    "            for iw, word in enumerate(review):\n",
    "                if iw >= self.maxlen: break\n",
    "                else:\n",
    "                    if word in self.model.vocab:\n",
    "                        vector[idx][iw] = self.model[word]\n",
    "            #sys.stdout.write('\\r{:5.2f}%'.format(100*(idx+1)/n))\n",
    "        #sys.stdout.write('\\rDone     \\n\\n')                    \n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_max_len  = 256\n",
    "vectorizer   = ReviewVectorizer(model, seq_max_len, EMB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set(sentences, labels, lenghts, batch_size, vectorizer):\n",
    "    N = len(sentences)\n",
    "    for i in range(0, N, batch_size):\n",
    "        batch_sent = sentences[i: i + batch_size]\n",
    "        embeddings = vectorizer.transform(batch_sent)\n",
    "        batch_lebl = np.reshape(np.array(labels[i: i + batch_size] , dtype = np.int32), (-1, 1))\n",
    "        seq_lenght = np.array(lenghts[i: i + batch_size], dtype = np.int32)\n",
    "        yield embeddings, batch_lebl, seq_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 10\n",
    "#gen = get_training_set(sentences, labels, lenghts, batch_size, vectorizer)\n",
    "#batch1, batch2, batch3 = next(gen)\n",
    "#print('review_shape : ', batch1.shape, ', label_shape: ', batch2.shape,', seq_shape : ', batch3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def getWeights(shape):\n",
    "    initVar = weights = tf.truncated_normal_initializer(stddev=0.1)\n",
    "    #return tf.Variable(tf.truncated_normal( shape  = shape,\n",
    "    #                                        stddev = 0.01), name = 'W')\n",
    "    return tf.get_variable('W',\n",
    "                            dtype = tf.float32,\n",
    "                            shape = shape,\n",
    "                            initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def getBiases(shape):\n",
    "    #return tf.Variable(tf.zeros(0.0, shape=shape, dtype = tf.float32), name = 'b')\n",
    "    initVar = tf.constant(0.0, shape = shape, dtype = tf.float32)\n",
    "    return tf.get_variable('b',\n",
    "                            dtype = tf.float32,\n",
    "                            initializer = initVar)\n",
    "\n",
    "def RNN(input_rev, vocabulary_size, emb_size, n_hidden, batch_size, seq_max_len, seq_len, num_layers):  \n",
    "    embedding = tf.Variable(tf.random_uniform((vocabulary_size, emb_size), -1, 1))\n",
    "    embed     = tf.nn.embedding_lookup(embedding, input_rev)\n",
    "    \n",
    "    lstms_fw = [tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(n_hidden) for _ in range(num_layers)]\n",
    "    cell_fw  = tf.contrib.rnn.MultiRNNCell(lstms_fw)\n",
    "\n",
    "    lstms_bw = [tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(n_hidden) for _ in range(num_layers)]\n",
    "    cell_bw  = tf.contrib.rnn.MultiRNNCell(lstms_bw)\n",
    "    \n",
    "    cell_fw  = tf.nn.rnn_cell.DropoutWrapper(cell_fw, output_keep_prob=0.8)\n",
    "    cell_bw  = tf.nn.rnn_cell.DropoutWrapper(cell_bw, output_keep_prob=0.8)\n",
    "    \n",
    "    #initial_state   = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
    "                                                      cell_bw,\n",
    "                                                      embed,\n",
    "                                                      sequence_length=seq_len,\n",
    "                                                      dtype=tf.float32)\n",
    "    #outputs, states = tf.nn.dynamic_rnn(cell, input_rev, initial_state = initial_state)\n",
    "    \n",
    "    \n",
    "    index   = tf.range(0, batch_size) * seq_max_len + (seq_len - 1)\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "    out     = tf.layers.dense(inputs=outputs, units=40)\n",
    "    out     = tf.nn.dropout(out, keep_prob = 0.8)\n",
    "    out     = tf.layers.dense(inputs=out, units=1)\n",
    "    #out     = tf.matmul(outputs, weights) + biases\n",
    "    #out     = tf.matmul(outputs[:, -1], weights) + biases\n",
    "    res     = tf.sigmoid(out, 'sigmoid')\n",
    "    return res   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim        = EMB_SIZE\n",
    "num_hidden_units = 20\n",
    "out_dim          = 1\n",
    "number_of_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate  = 0.01\n",
    "batch_size     = 1000\n",
    "display_freq   = 10\n",
    "training_steps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X       = tf.placeholder(tf.float32, [None, seq_max_len, input_dim], name = 'input')\n",
    "seqLen  = tf.placeholder(tf.int32  , [None], name = 'seq_len')\n",
    "y       = tf.placeholder(tf.int32,   [None, 1], name = 'labels')\n",
    "\n",
    "with tf.variable_scope(\"RNN\", reuse=tf.AUTO_REUSE):\n",
    "    pred_out = RNN(X, num_hidden_units, batch_size, seq_max_len, seqLen, number_of_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"Train\", reuse=tf.AUTO_REUSE):\n",
    "    #cost       = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = pred_out))\n",
    "    #assert y.shape == pred_out.shape\n",
    "    \n",
    "    cost       = tf.losses.mean_squared_error(y, pred_out)\n",
    "    train_op   = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    pred_class = tf.greater(pred_out,0.5)\n",
    "    acc_mes    = tf.equal(pred_class, tf.equal(y,1), name = 'correct_pred')\n",
    "    acc        = tf.reduce_mean(tf.cast(acc_mes, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :    1, training loss = 0.233, testing accuracy = 0.672\n",
      "epoch :    2, training loss = 0.185, testing accuracy = 0.726\n",
      "epoch :    3, training loss = 0.166, testing accuracy = 0.739\n",
      "epoch :    4, training loss = 0.156, testing accuracy = 0.755\n",
      "epoch :    5, training loss = 0.149, testing accuracy = 0.755\n",
      "epoch :    6, training loss = 0.145, testing accuracy = 0.750\n",
      "epoch :    7, training loss = 0.145, testing accuracy = 0.752\n",
      "epoch :    8, training loss = 0.140, testing accuracy = 0.749\n",
      "epoch :    9, training loss = 0.138, testing accuracy = 0.750\n",
      "epoch :   10, training loss = 0.139, testing accuracy = 0.755\n"
     ]
    }
   ],
   "source": [
    "init     = tf.global_variables_initializer()\n",
    "\n",
    "N = len(sentences)\n",
    "\n",
    "X_train = sentences[:40000]\n",
    "y_train = labels[:40000]\n",
    "l_train = lenghts[:40000]\n",
    "\n",
    "X_test  = sentences[40000:]\n",
    "y_test  = labels[40000:]\n",
    "l_test  = lenghts[40000:]\n",
    "\n",
    "assert len(X_train) == len(y_train) == len(l_train) == 40000\n",
    "assert len(X_test)  == len(y_test)  == len(l_test)  == 10000\n",
    "\n",
    "train_loss = []\n",
    "test_acc   = []\n",
    "\n",
    "fmt = 'epoch : {:4d}, training loss = {:4.3f}, testing accuracy = {:4.3f}'\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(init)\n",
    "    #print('-------Training-------\\n')\n",
    "    for ep in range(1, training_steps + 1):\n",
    "        gen = get_training_set(X_train, y_train, l_train, batch_size, vectorizer)\n",
    "        loss_t = []\n",
    "        for i in range(1, len(X_train) // batch_size + 1):\n",
    "            x_batch , y_batch, seq_len_batch = next(gen)\n",
    "            _, loss = sess.run([train_op, cost], feed_dict={X:x_batch, y:y_batch, seqLen: seq_len_batch})\n",
    "            loss_t.append(loss)\n",
    "        \n",
    "        train_loss.append(sum(loss_t)/len(loss_t))\n",
    "        #print('\\tTraining loss = {:4.3f}'.format(sum(loss_t)/len(loss_t)))\n",
    "        \n",
    "        gen_test = get_training_set(X_test, y_test, l_test, batch_size, vectorizer)\n",
    "        acc_t    = []\n",
    "        \n",
    "        for i in range(len(X_test) // batch_size):\n",
    "            x_batch , y_batch, seq_len_batch = next(gen_test)\n",
    "            accuracy = sess.run([acc], feed_dict={X:x_batch, y:y_batch, seqLen: seq_len_batch})\n",
    "            acc_t.append(accuracy[0])\n",
    "        \n",
    "        test_acc.append(sum(acc_t)/len(acc_t))\n",
    "        print(fmt.format(ep, sum(loss_t)/len(loss_t), sum(acc_t)/len(acc_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This lines are for plot error on each epoch\n",
    "\n",
    "ep  = np.arange(1, training_steps + 1, 1)\n",
    "fig, ax   = plt.subplots(figsize=(14, 8))\n",
    "l1        = ax.plot(ep, train_loss)\n",
    "ax.set(xlabel='Epoch', ylabel='Cost', title='Recurrent Neural Network - Training Loss')\n",
    "ax.axis([0.0, training_steps + 0.5, 0.1, train_loss[0]+0.01])\n",
    "#plt.legend([l1, l2],[\"Training\",\"Validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "l2      = ax.plot( ep, test_acc)\n",
    "ax.set(xlabel='Epoch', ylabel='Cost', title='Recurrent Neural Network - Testing Accuracy ')\n",
    "ax.axis([0.8, training_steps + 0.5, test_acc[0]-0.01, test_acc[-1]+0.01])\n",
    "#plt.legend([l1, l2],[\"Training\",\"Validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we successfully trained a model to predict the sentiment of a movie review. Unfortunately, if we'd close this IPython notebook at this point, we'd have to go through the whole learning process again and again if we'd want to make a prediction on \"new data.\"\n",
    "\n",
    "So, to reuse this model, we could use the [`pickle`](https://docs.python.org/3.5/library/pickle.html) module to \"serialize a Python object structure\". Or even better, we could use the [`joblib`](https://pypi.python.org/pypi/joblib) library, which handles large NumPy arrays more efficiently.\n",
    "\n",
    "To install:\n",
    "conda install -c anaconda joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 3: compare  with your Neural Network\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "joblib.dump(vectorizer, './vectorizer.pkl')\n",
    "joblib.dump(net,'./net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us restart this IPython notebook and check if the we can load our serialized objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = joblib.load('./vectorizer.pkl')\n",
    "net        = joblib.load('./net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the `tokenizer`, `HashingVectorizer`, and the tranined logistic regression model, we can use it to make predictions on new data, which can be useful, for example, if we'd want to embed our classifier into a web application -- a topic for another IPython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True : Good comment, False: Bad comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 100) (1, 1) (1,) [4]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'seq_len_2' with dtype int32 and shape [?]\n\t [[node seq_len_2 (defined at <ipython-input-47-68dc78407083>:2)  = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node RNN_2/sigmoid/_45}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_434_RNN_2/sigmoid\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'seq_len_2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-68dc78407083>\", line 2, in <module>\n    seqLen  = tf.placeholder(tf.int32  , [None], name = 'seq_len')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5206, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'seq_len_2' with dtype int32 and shape [?]\n\t [[node seq_len_2 (defined at <ipython-input-47-68dc78407083>:2)  = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node RNN_2/sigmoid/_45}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_434_RNN_2/sigmoid\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'seq_len_2' with dtype int32 and shape [?]\n\t [[{{node seq_len_2}} = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node RNN_2/sigmoid/_45}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_434_RNN_2/sigmoid\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-84e2a25fb9db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_sam\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'seq_len_2' with dtype int32 and shape [?]\n\t [[node seq_len_2 (defined at <ipython-input-47-68dc78407083>:2)  = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node RNN_2/sigmoid/_45}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_434_RNN_2/sigmoid\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'seq_len_2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-68dc78407083>\", line 2, in <module>\n    seqLen  = tf.placeholder(tf.int32  , [None], name = 'seq_len')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5206, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'seq_len_2' with dtype int32 and shape [?]\n\t [[node seq_len_2 (defined at <ipython-input-47-68dc78407083>:2)  = Placeholder[dtype=DT_INT32, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node RNN_2/sigmoid/_45}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_434_RNN_2/sigmoid\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "example = ['I loved this movie']\n",
    "m  = tokenizer(example[0])\n",
    "X_sam = vectorizer.transform([m])\n",
    "y_sam = np.reshape(np.array([1]), (1,1))\n",
    "seq_len_sam = np.array([len(m)], dtype=np.int32)\n",
    "\n",
    "print(X_sam.shape, y_sam.shape, seq_len_sam.shape, seq_len_sam)\n",
    "\n",
    "g = tf.get_default_graph()\n",
    "with tf.Session(graph = g) as sess:\n",
    "    accuracy = sess.run([pred_out], feed_dict={X:X_sam})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['This movie was great!']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I didn't like this movie\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['I did not like this movie']\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I don't like this movie\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In complex sentences the result is not the correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I love the actor but the history was the worst, I don't recommend this one\"]\n",
    "m  = tokenizer(example[0])\n",
    "X = vectorizer.transform([m])\n",
    "net.predSentiment(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
